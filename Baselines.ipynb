{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate results for FairTopk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairsearchcore.models import FairScoreDoc\n",
    "import fairsearchcore as fsc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/farzan/opt/anaconda3/lib/python3.7/site-packages/fairsearchcore/fair.py:165: UserWarning: Library has not been tested with values outside this range\n",
      "  warnings.warn(\"Library has not been tested with values outside this range\")\n"
     ]
    }
   ],
   "source": [
    "def load_data(year, prt_group):\n",
    "    \"\"\"\n",
    "    Load data in a format compatible with fairsearchcore package for fairtopk algorithm.\n",
    "    \"\"\"\n",
    "    data =  pd.read_csv('./data/ICLR'+str(year)+'.data')\n",
    "    k = int(np.sum(data.h_c))\n",
    "    p = 1-np.sum(data[prt_group])/data.shape[0]\n",
    "    rankings = list()\n",
    "    for idx in data.s.argsort()[::-1]:\n",
    "        if data.loc[idx,prt_group] == 1:\n",
    "            rankings.append( FairScoreDoc(idx, data.loc[idx,'s'], False))\n",
    "        if data.loc[idx,prt_group] == 0:\n",
    "            rankings.append( FairScoreDoc(idx, data.loc[idx,'s'], True))\n",
    "    return rankings, k, p, data\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "for year in [2017,2018,2019,2020]:\n",
    "    for prt_group in ['top', 'famous']:\n",
    "        rankings, k, p, data = load_data(year,prt_group)\n",
    "        fair = fsc.Fair(k, p, alpha)\n",
    "        re_ranked = fair.re_rank(rankings)\n",
    "        eps = 1/len(rankings)\n",
    "        h = np.zeros(len(rankings))\n",
    "        for i,item in enumerate(re_ranked):\n",
    "            h[item.id] = 1 - i*eps\n",
    "        out_df = pd.DataFrame({'h': h, prt_group : data[prt_group]})\n",
    "        out_df.to_csv('./data/Baseline/ICLR'+str(year)+str(prt_group)+'FairTopK.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate results for ROC(EOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import aif360\n",
    "from aif360.algorithms.postprocessing.calibrated_eq_odds_postprocessing import CalibratedEqOddsPostprocessing\n",
    "from aif360.algorithms.postprocessing.reject_option_classification import RejectOptionClassification\n",
    "from codes.utils import power_mean, binarize\n",
    "\n",
    "def load_data(year, prt_group):\n",
    "    \"\"\"\n",
    "    Load data in a format compatible with aif360 package.\n",
    "    \"\"\"\n",
    "    data =  pd.read_csv('./data/ICLR'+str(year)+'.data')\n",
    "    data['s'] = data['s']/10\n",
    "    data['s_hat'] = binarize(data['s'], int(np.sum(data['h_c'])))\n",
    "    dataset = aif360.datasets.BinaryLabelDataset(\n",
    "        favorable_label=1,\n",
    "        unfavorable_label=0,\n",
    "        df=data,\n",
    "        label_names=['s_hat'],\n",
    "        protected_attribute_names=[prt_group])\n",
    "    dataset.scores = data['s'].to_numpy().reshape((data.shape[0],1))\n",
    "    return dataset, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "metric_ub = 0.02\n",
    "metric_lb = -0.02\n",
    "for year in [2017, 2018, 2019,2020]:\n",
    "    print(year )\n",
    "    for prt_group in ['top', 'famous']:\n",
    "        dataset, df = load_data(year, prt_group)\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=[{prt_group: 0}], \n",
    "                                         privileged_groups= [{prt_group: 1}], \n",
    "                                         low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                          num_class_thresh=100, num_ROC_margin=50,\n",
    "                                          metric_name= \"Equal opportunity difference\",\n",
    "                                          metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        dataset_pred = dataset.copy(deepcopy = True)\n",
    "        ROC = ROC.fit(dataset, dataset_pred)\n",
    "        dataset_transf_pred = ROC.predict(dataset)\n",
    "        h = dataset_transf_pred.labels[:,0]\n",
    "        out_df = pd.DataFrame({'h': h, prt_group :df[prt_group]})\n",
    "        out_df.to_csv('./data/Baseline/ICLR'+str(year)+str(prt_group)+'ROC(EOD).csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate results for ROC(SPD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "metric_ub = 0.02\n",
    "metric_lb = -0.02\n",
    "for year in [2017, 2018, 2019,2020]:\n",
    "    print(year )\n",
    "    for prt_group in ['top', 'famous']:\n",
    "        dataset, df = load_data(year, prt_group)\n",
    "        ROC = RejectOptionClassification(unprivileged_groups=[{prt_group: 0}], \n",
    "                                         privileged_groups= [{prt_group: 1}], \n",
    "                                         low_class_thresh=0.01, high_class_thresh=0.99,\n",
    "                                          num_class_thresh=100, num_ROC_margin=50,\n",
    "                                          metric_name= \"Statistical parity difference\",\n",
    "                                          metric_ub=metric_ub, metric_lb=metric_lb)\n",
    "        dataset_pred = dataset.copy(deepcopy = True)\n",
    "        ROC = ROC.fit(dataset, dataset_pred)\n",
    "        dataset_transf_pred = ROC.predict(dataset)\n",
    "        h = dataset_transf_pred.labels[:,0]\n",
    "        out_df = pd.DataFrame({'h': h, prt_group :df[prt_group]})\n",
    "        out_df.to_csv('./data/Baseline/ICLR'+str(year)+str(prt_group)+'ROC(SPD).csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate results for CEP (FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "for year in [2017, 2018, 2019,2020]:\n",
    "    print(year )\n",
    "    for prt_group in ['top', 'famous']:\n",
    "        dataset, df = load_data(year, prt_group)\n",
    "        cpp = CalibratedEqOddsPostprocessing(unprivileged_groups=[{prt_group: 0}], \n",
    "                                         privileged_groups= [{prt_group: 1}], cost_constraint='fpr',seed=1)\n",
    "        dataset_pred = dataset.copy(deepcopy = True)\n",
    "        cpp = cpp.fit(dataset, dataset_pred)\n",
    "        dataset_transf_pred = cpp.predict(dataset)\n",
    "        h = dataset_transf_pred.labels[:,0]\n",
    "        out_df = pd.DataFrame({'h': h, prt_group :df[prt_group]})\n",
    "        out_df.to_csv('./data/Baseline/ICLR'+str(year)+str(prt_group)+'CPP(FPR).csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
